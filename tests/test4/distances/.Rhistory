p = ggplot(gg2, aes(x = H, y = S, fill = ValidH)) + geom_tile()
p = p + labs(title = 'Best values of H', x = 'Shannon entropy (H)', y = 'Minimun number of reads to adjust H')
p = p + theme(plot.title = element_text(hjust = 0.5))
p
ggsave(file = paste0('Haccuracy.svg'), plot = p, width = 10, height = 8)
# S
p = ggplot(gg2, aes(x = H, y = S, fill = ValidS)) + geom_tile()
p = p + labs(title = 'Best values of S', x = 'Shannon entropy (H)', y = 'Number of Species (S)', fill = 'Minimun number of reads to adjust S')
p = p + theme(plot.title = element_text(hjust = 0.5))
p
ggsave(file = paste0('Saccuracy.svg'), plot = p, width = 10, height = 8)
# Best
p = ggplot(gg2, aes(x = H, y = S, fill = Reads)) + geom_tile(colour = 'white') + scale_fill_brewer(palette = 'Blues', direction = 1)
p = p + labs(title = 'Choosing the minimun number of reads', x = 'Shannon entropy (H)', y = 'Number of Species (S)', fill = 'Minimun number of reads to adjust S and H')
p = p + theme(plot.title = element_text(hjust = 0.5))
p
ggsave(file = paste0('READS.svg'), plot = p)
rr = dd
gg2 = expand.grid(H = Hvalues, S = Svalues)
gg2$ValidH = rep(NA, nrow(gg2))
gg2$ValidS = rep(NA, nrow(gg2))
gg2$Reads = rep(NA, nrow(gg2))
rownames(gg2) = paste0(gg2$H, '_', gg2$S)
cutoff = 0.1
#H
for (r in sort(reads)){
srr = rr[rr$reads == r, ]
# Fix a relative error to be considered acceptable: Ex: 0.10
for (i in c(1:nrow(srr))) {
print(r)
if (is.na(srr$Herror[i])){
next()
} else if(gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidH'] != 0 & !is.na(gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidH'])){
next()
} else {
if (abs(srr$Herror[i]) < cutoff){
gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidH'] = r # save minimun number of reads to satisfy this criteria
}else if (abs(srr$Herror[i]) > cutoff){
gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidH'] = 0
}else{next()}
}
}
}
#S
for (r in sort(reads)){
srr = rr[rr$reads == r, ]
# Fix a relative error to be considered acceptable: Ex: 0.10
for (i in c(1:nrow(srr))) {
print(r)
if (is.na(srr$Serror[i])){
next()
} else if(gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidS'] != 0 & !is.na(gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidS'])){
next()
} else {
if (abs(srr$Serror[i]) < cutoff){
gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidS'] = r # save minimun number of reads to satisfy this criteria
}else if (abs(srr$Serror[i]) > cutoff){
gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidS'] = 0
}else{next()}
}
}
}
# BEST
for (i in c(1:nrow(gg2))){
if ((!is.na(gg2[i, 'ValidH']) & !is.na(gg2[i, 'ValidS']) & (gg2[i, 'ValidH'] != 0 & gg2[i, 'ValidS'] != 0 ))){
#print(gg2[i, ])
gg2[i, 'Reads'] = max(gg2[i, 'ValidH'], gg2[i, 'ValidS'])
} else if ((!is.na(gg2[i, 'ValidH']) & !is.na(gg2[i, 'ValidS']) & (gg2[i, 'ValidH'] == 0 | gg2[i, 'ValidS'] == 0 ))){
gg2[i, 'Reads'] = 'Higher relative error'
}
}
gg2$Reads[gg2$Reads == 0] = 'Higher relative error'
gg2$Reads = factor(gg2$Reads, levels = c('Higher relative error', as.character(reads)))
#Plots
# H
p = ggplot(gg2, aes(x = H, y = S, fill = ValidH)) + geom_tile()
p = p + labs(title = 'Best values of H', x = 'Shannon entropy (H)', y = 'Minimun number of reads to adjust H')
p = p + theme(plot.title = element_text(hjust = 0.5))
p
ggsave(file = paste0('Haccuracy.svg'), plot = p, width = 10, height = 8)
# S
p = ggplot(gg2, aes(x = H, y = S, fill = ValidS)) + geom_tile()
p = p + labs(title = 'Best values of S', x = 'Shannon entropy (H)', y = 'Number of Species (S)', fill = 'Minimun number of reads to adjust S')
p = p + theme(plot.title = element_text(hjust = 0.5))
p
ggsave(file = paste0('Saccuracy.svg'), plot = p, width = 10, height = 8)
# Best
p = ggplot(gg2, aes(x = H, y = S, fill = Reads)) + geom_tile(colour = 'white') + scale_fill_brewer(palette = 'Blues', direction = 1)
p = p + labs(title = 'Choosing the minimun number of reads', x = 'Shannon entropy (H)', y = 'Number of Species (S)', fill = 'Minimun number of reads to adjust S and H')
p = p + theme(plot.title = element_text(hjust = 0.5))
p
ggsave(file = paste0('READS.svg'), plot = p)
rr = dd
gg2 = expand.grid(H = Hvalues, S = Svalues)
gg2$ValidH = rep(NA, nrow(gg2))
gg2$ValidS = rep(NA, nrow(gg2))
gg2$Reads = rep(NA, nrow(gg2))
rownames(gg2) = paste0(gg2$H, '_', gg2$S)
cutoff = 0.05
#H
for (r in sort(reads)){
srr = rr[rr$reads == r, ]
# Fix a relative error to be considered acceptable: Ex: 0.10
for (i in c(1:nrow(srr))) {
print(r)
if (is.na(srr$Herror[i])){
next()
} else if(gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidH'] != 0 & !is.na(gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidH'])){
next()
} else {
if (abs(srr$Herror[i]) < cutoff){
gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidH'] = r # save minimun number of reads to satisfy this criteria
}else if (abs(srr$Herror[i]) > cutoff){
gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidH'] = 0
}else{next()}
}
}
}
#S
for (r in sort(reads)){
srr = rr[rr$reads == r, ]
# Fix a relative error to be considered acceptable: Ex: 0.10
for (i in c(1:nrow(srr))) {
print(r)
if (is.na(srr$Serror[i])){
next()
} else if(gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidS'] != 0 & !is.na(gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidS'])){
next()
} else {
if (abs(srr$Serror[i]) < cutoff){
gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidS'] = r # save minimun number of reads to satisfy this criteria
}else if (abs(srr$Serror[i]) > cutoff){
gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidS'] = 0
}else{next()}
}
}
}
# BEST
for (i in c(1:nrow(gg2))){
if ((!is.na(gg2[i, 'ValidH']) & !is.na(gg2[i, 'ValidS']) & (gg2[i, 'ValidH'] != 0 & gg2[i, 'ValidS'] != 0 ))){
#print(gg2[i, ])
gg2[i, 'Reads'] = max(gg2[i, 'ValidH'], gg2[i, 'ValidS'])
} else if ((!is.na(gg2[i, 'ValidH']) & !is.na(gg2[i, 'ValidS']) & (gg2[i, 'ValidH'] == 0 | gg2[i, 'ValidS'] == 0 ))){
gg2[i, 'Reads'] = 'Higher relative error'
}
}
gg2$Reads[gg2$Reads == 0] = 'Higher relative error'
gg2$Reads = factor(gg2$Reads, levels = c('Higher relative error', as.character(reads)))
#Plots
# H
p = ggplot(gg2, aes(x = H, y = S, fill = ValidH)) + geom_tile()
p = p + labs(title = 'Best values of H', x = 'Shannon entropy (H)', y = 'Minimun number of reads to adjust H')
p = p + theme(plot.title = element_text(hjust = 0.5))
p
#ggsave(file = paste0('Haccuracy.svg'), plot = p, width = 10, height = 8)
# S
p = ggplot(gg2, aes(x = H, y = S, fill = ValidS)) + geom_tile()
p = p + labs(title = 'Best values of S', x = 'Shannon entropy (H)', y = 'Number of Species (S)', fill = 'Minimun number of reads to adjust S')
p = p + theme(plot.title = element_text(hjust = 0.5))
p
#ggsave(file = paste0('Saccuracy.svg'), plot = p, width = 10, height = 8)
# Best
p = ggplot(gg2, aes(x = H, y = S, fill = Reads)) + geom_tile(colour = 'white') + scale_fill_brewer(palette = 'Blues', direction = 1)
p = p + labs(title = 'Choosing the minimun number of reads', x = 'Shannon entropy (H)', y = 'Number of Species (S)', fill = 'Minimun number of reads to adjust S and H')
p = p + theme(plot.title = element_text(hjust = 0.5))
p
#ggsave(file = paste0('READS.svg'), plot = p)
rr = dd
gg2 = expand.grid(H = Hvalues, S = Svalues)
gg2$ValidH = rep(NA, nrow(gg2))
gg2$ValidS = rep(NA, nrow(gg2))
gg2$Reads = rep(NA, nrow(gg2))
rownames(gg2) = paste0(gg2$H, '_', gg2$S)
cutoff = 0.20
#H
for (r in sort(reads)){
srr = rr[rr$reads == r, ]
# Fix a relative error to be considered acceptable: Ex: 0.10
for (i in c(1:nrow(srr))) {
print(r)
if (is.na(srr$Herror[i])){
next()
} else if(gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidH'] != 0 & !is.na(gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidH'])){
next()
} else {
if (abs(srr$Herror[i]) < cutoff){
gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidH'] = r # save minimun number of reads to satisfy this criteria
}else if (abs(srr$Herror[i]) > cutoff){
gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidH'] = 0
}else{next()}
}
}
}
#S
for (r in sort(reads)){
srr = rr[rr$reads == r, ]
# Fix a relative error to be considered acceptable: Ex: 0.10
for (i in c(1:nrow(srr))) {
print(r)
if (is.na(srr$Serror[i])){
next()
} else if(gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidS'] != 0 & !is.na(gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidS'])){
next()
} else {
if (abs(srr$Serror[i]) < cutoff){
gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidS'] = r # save minimun number of reads to satisfy this criteria
}else if (abs(srr$Serror[i]) > cutoff){
gg2[paste0(srr$H[i], '_', srr$S[i]), 'ValidS'] = 0
}else{next()}
}
}
}
# BEST
for (i in c(1:nrow(gg2))){
if ((!is.na(gg2[i, 'ValidH']) & !is.na(gg2[i, 'ValidS']) & (gg2[i, 'ValidH'] != 0 & gg2[i, 'ValidS'] != 0 ))){
#print(gg2[i, ])
gg2[i, 'Reads'] = max(gg2[i, 'ValidH'], gg2[i, 'ValidS'])
} else if ((!is.na(gg2[i, 'ValidH']) & !is.na(gg2[i, 'ValidS']) & (gg2[i, 'ValidH'] == 0 | gg2[i, 'ValidS'] == 0 ))){
gg2[i, 'Reads'] = 'Higher relative error'
}
}
gg2$Reads[gg2$Reads == 0] = 'Higher relative error'
gg2$Reads = factor(gg2$Reads, levels = c('Higher relative error', as.character(reads)))
#Plots
# H
p = ggplot(gg2, aes(x = H, y = S, fill = ValidH)) + geom_tile()
p = p + labs(title = 'Best values of H', x = 'Shannon entropy (H)', y = 'Minimun number of reads to adjust H')
p = p + theme(plot.title = element_text(hjust = 0.5))
p
#ggsave(file = paste0('Haccuracy.svg'), plot = p, width = 10, height = 8)
# S
p = ggplot(gg2, aes(x = H, y = S, fill = ValidS)) + geom_tile()
p = p + labs(title = 'Best values of S', x = 'Shannon entropy (H)', y = 'Number of Species (S)', fill = 'Minimun number of reads to adjust S')
p = p + theme(plot.title = element_text(hjust = 0.5))
p
#ggsave(file = paste0('Saccuracy.svg'), plot = p, width = 10, height = 8)
# Best
p = ggplot(gg2, aes(x = H, y = S, fill = Reads)) + geom_tile(colour = 'white') + scale_fill_brewer(palette = 'Blues', direction = 1)
p = p + labs(title = 'Choosing the minimun number of reads', x = 'Shannon entropy (H)', y = 'Number of Species (S)', fill = 'Minimun number of reads to adjust S and H')
p = p + theme(plot.title = element_text(hjust = 0.5))
p
#ggsave(file = paste0('READS.svg'), plot = p)
library(ggplot2)
library(reshape2)
library(vegan)
library(dplyr)
library(data.table)
setwd("~/Documentos/PROYECTOS/MALASPINA/")
Widb = read.table('dREP/data_tables/Widb.csv', row.names = 1, header = T, stringsAsFactors = F, sep = ',') # Winning genomes' checkM information
Cdb = read.table('dREP/data_tables/Cdb.csv', row.names = 1, header = T, stringsAsFactors = F, sep = ',') # Genomes and cluster designations
Chdb = read.table('dREP/data_tables/CdbF.csv', header = T, stringsAsFactors = F, sep = ',') # CheckM results for Bdb
Mdb = read.table('dREP/data_tables/Mdb.csv', header = T, stringsAsFactors = F, sep = ',') # Raw results of MASH comparisons
Ndb = read.table('dREP/data_tables/Ndb.csv', header = T, stringsAsFactors = F, sep = ',') # Raw results of ANIn comparisons
Sdb = read.table('dREP/data_tables/Sdb.csv', row.names = 1, header = T, stringsAsFactors = F, sep = ',') # Scoring information
Wdb = read.table('dREP/data_tables/Wdb.csv', row.names = 1, header = T, stringsAsFactors = F, sep = ',') # Winning genomes
metadata = read.table('~/Documentos/PROYECTOS/MALASPINA/metadata.csv', header = T, row.names = 2, stringsAsFactors = F, sep = '\t', check.names = F, dec = ',')
colnames(metadata) = c('N', 'done', 'available_metadata', 'SQMrun', 'assembly', 'Leg', 'CodeMP', 'Date',
'Station', 'DepthEst', 'Depth', 'MaxZ', 'Lat', 'Long', 'Longhurst', 'SamplingMethod',
'Cast', 'Niskin', 'Barcode', 'Day', 'Nreplicate', 'FilterSize', 'Vreplicate',
'Temp', 'Cond', 'Ox_v', 'Fluo', 'PAR', 'SPAR', 'Turb', 'Batt', 'Sal', 'Ox',
'02DNA', '3DNA', '02RNA', '3RNA')
meta = metadata[,c('Station', 'Depth', 'MaxZ', 'Longhurst', 'FilterSize', 'Temp', 'Cond', 'Ox_v', 'Fluo', 'PAR', 'SPAR', 'Turb', 'Batt', 'Sal', 'Ox')]
#rownames(metadata) = paste0('MP', metadata$available_metadata)
#
Cdb$sample = sapply(strsplit(rownames(Cdb), '[.]'), "[", 4)
Wi = Widb[,c('score', 'completeness', 'contamination', 'strain_heterogeneity', 'size', 'cluster', 'cluster_members')]
# Select clusters with more than 1 bin:
Wi_multi = Wi[Wi$cluster_members > 1, ]
par(mfrow=c(1, 2))
hist(Wi$cluster_members, main = 'Members per cluster', col = 'yellowgreen', xlab = 'Cluster members', ylab = 'Frequency')
hist(Wi_multi$cluster_members, main = 'Members per cluster (>1)', col = 'yellowgreen', xlab = 'Cluster members', ylab = 'Frequency')
par(mfrow=c(1, 1))
dim(Wi)
dim(Wi_multi)
View(Ndb)
Cdb$Station = meta[Cdb$sample, 'Station']
Cdb$Depth = meta[Cdb$sample, 'Depth']
Cdb$Longhurst = meta[Cdb$sample, 'Longhurst']
Cdb$FilterSize = meta[Cdb$sample, 'FilterSize']
Cdb$Temp = meta[Cdb$sample, 'Temp']
Cdb$Cond = meta[Cdb$sample, 'Cond']
Cdb$Ox_v = meta[Cdb$sample, 'Ox_v']
Cdb$Fluo = meta[Cdb$sample, 'Fluo']
Cdb$PAR = meta[Cdb$sample, 'PAR']
Cdb$SPAR = meta[Cdb$sample, 'SPAR']
Cdb$Turb = meta[Cdb$sample, 'Turb']
Cdb$Batt = meta[Cdb$sample, 'Batt']
Cdb$Sal = meta[Cdb$sample, 'Sal']
Cdb$Ox = meta[Cdb$sample, 'Ox']
Cdb_multi = Cdb[Cdb$secondary_cluster %in% Wi_multi$cluster & Cdb$FilterSize == 0.2,]
Cdb_multi$secondary_cluster = as.factor(Cdb_multi$secondary_cluster)
plot(Cdb_multi$secondary_cluster, Cdb_multi$Depth, main = 'Depth')
SC_Temp = Cdb_multi %>%  group_by(primary_cluster) %>% summarise(sd = sd(Temp), n = n())
Temp = SC_Temp %>% group_by(n) %>% summarise(mean = mean(sd))
plot(as.factor(SC_Temp$n), SC_Temp$sd, main = 'Temp', xlab = 'Members per cluster', ylab = 'sd of Temp' ,col = 'cornflowerblue')
SC_Ox = Cdb_multi %>%  group_by(secondary_cluster) %>% summarise(sd = sd(Ox), n = n())
plot(as.factor(SC_Ox$n), SC_Ox$sd, main = 'Ox', xlab = 'Members per cluster', ylab = 'sd of Ox' ,col = 'cornflowerblue')
SC_Depth = Cdb_multi %>%  group_by(secondary_cluster) %>% summarise(sd = sd(Depth), n = n())
plot(as.factor(SC_Depth$n), SC_Depth$sd, main = 'Depth', xlab = 'Members per cluster', ylab = 'sd of Depth' ,col = 'cornflowerblue')
library('maps')
colores=rep('gray88',length(a$names))
#Me interesa el estado a$names[63]
colores[63]='tomato3'
a= map('county','Wisconsin', fill=T, col=colores)
install.packages("maps")
library('maps')
colores=rep('gray88',length(a$names))
#Me interesa el estado a$names[63]
colores[63]='tomato3'
a= map('county','Wisconsin', fill=T, col=colores)
colores=rep('gray88',length(a$names))
#Map Wisconsin
library('maps')
a= map('county','Wisconsin', fill=T, col=colores)
colores=rep('gray88',length(a$names))
#Me interesa el estado a$names[63]
colores[63]='tomato3'
a= map('county','Wisconsin', fill=T, col=colores)
a= map('county','Wisconsin', fill=T)
str(map('county','Wisconsin', fill=T))
dim(map('county','Wisconsin', fill=T))
str(map('county','Wisconsin', fill=T)) # length $names -> 72
colores=rep('gray88', 72)
#Me interesa el estado a$names[63]
colores[63]='tomato3'
a= map('county','Wisconsin', fill=T, col=colores)
seq(10000, 10000000, 20000)
length(seq(10000, 10000000, 20000))
length(seq(10000, 10000000, 50000))
seq(10000, 10000000, 50000)
View(Ndb)
lm(c(1,2,3)~c(4,5,6))
summary(lm(c(1,2,3)~c(4,5,6)))
summary(lm(c(1,2,3)~c(4,5,7)))
summary(lm(c(1:10)~c(1:10)))
setwd("~/opt/MMs/tests/TAXA")
library(ggplot2)
library(reshape2)
projectName = 'Freshwaters_master'
enviro = 'Aquatic.Freshwaters'
originFile = 'SpeciesperEnviro.tsv'
origin = read.table(originFile, header = T, row.names=1, stringsAsFactors = F, check.names = F)
env = origin[, enviro, drop = F]
env[env==0] = 0.005 # we add this to include a little probability of absence taxons
# Create new df
df = as.data.frame(matrix(0, nrow = nrow(env), ncol = 101))
rownames(df) = rownames(env)
colnames(df) = c('origin', paste0('R_', c(1:100)))
df$origin = env[,1]
for (i in 1:100){
finalFile = paste0(projectName , i, '.pctax.tsv')
final = t(read.table(finalFile , sep = '\t', header = T, row.names = 1, check.names = F, stringsAsFactors = F))
for (tx in rownames(df)){
if (tx %in% rownames(final)){
df[tx, paste0('R_', i)] = final[tx,'counts']
} else { df[tx, paste0('R_', i)] = 0 }
}
}
dfnorm = as.data.frame(apply(df, 2, function(x) {x/sum(x)}*100))
dfnorm_sort = dfnorm[order(dfnorm$origin, decreasing = T),]
mean_of_replicas = as.data.frame(apply(dfnorm[, c(2:101)], 1, mean))
sd_of_replicas = as.data.frame(apply(dfnorm[, c(2:101)], 1, sd))
data2plot = cbind(dfnorm[, 'origin'], mean_of_replicas, sd_of_replicas, rownames(dfnorm))
colnames(data2plot) = c('origin', 'mean', 'sd', 'tax')
sink(paste0(projectName , '.', 'scatter_lm_taxonomy_subset_comparisons_100replicas.txt'))
print(summary(lm(data2plot$origin ~ data2plot$sd)))
sink()
p = ggplot(data2plot, aes(origin, mean)) + theme_light()
#p = p + geom_point() + geom_text(aes(label=tax),hjust=0, vjust=0)
p = p + geom_point() + geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd))
# Add regression line
p = p + geom_smooth(method = lm, formula = y ~ x)
p = p + geom_text(data = data2plot[data2plot$mean > 1,], aes(origin, mean, label = tax), hjust = 0, vjust = 0, size = 3)
p = p + labs(title = 'Subsetting taxa for an specific environment: \'Aquatic Freshwaters\'', x = 'Frequency of the different taxa in the reference of \'Aquatic Freshwaters\'', y = 'Mean of taxa abundance in 100 mocks of \'Aquatic Freshwaters\'')
p = p + theme(plot.title = element_text(hjust = 0.5))
p
library(ggplot2)
library(reshape2)
projectName = 'Freshwaters_master'
enviro = 'Aquatic.Freshwaters'
originFile = 'SpeciesperEnviro.tsv'
origin = read.table(originFile, header = T, row.names=1, stringsAsFactors = F, check.names = F)
env = origin[, enviro, drop = F]
env[env==0] = 0.005 # we add this to include a little probability of absence taxons
library(ggplot2)
library(reshape2)
projectName = 'Freshwaters_master'
enviro = 'Aquatic.Freshwaters'
originFile = 'SpeciesperEnviro.tsv'
origin = read.table(originFile, header = T, row.names=1, stringsAsFactors = F, check.names = F)
env = origin[, enviro, drop = F]
env[env==0] = 0.005 # we add this to include a little probability of absence taxons
library(ggplot2)
library(reshape2)
projectName = 'Freshwaters_master'
enviro = 'Aquatic.Freshwaters'
originFile = 'SpeciesperEnviro.tsv'
origin = read.table(originFile, header = T, row.names=1, stringsAsFactors = F, check.names = F)
env = origin[, enviro, drop = F]
env[env==0] = 0.005 # we add this to include a little probability of absence taxons
# Create new df
df = as.data.frame(matrix(0, nrow = nrow(env), ncol = 101))
rownames(df) = rownames(env)
colnames(df) = c('origin', paste0('R_', c(1:100)))
df$origin = env[,1]
for (i in 1:100){
finalFile = paste0(projectName , i, '.pctax.tsv')
final = t(read.table(finalFile , sep = '\t', header = T, row.names = 1, check.names = F, stringsAsFactors = F))
for (tx in rownames(df)){
if (tx %in% rownames(final)){
df[tx, paste0('R_', i)] = final[tx,'counts']
} else { df[tx, paste0('R_', i)] = 0 }
}
}
dfnorm = as.data.frame(apply(df, 2, function(x) {x/sum(x)}*100))
dfnorm_sort = dfnorm[order(dfnorm$origin, decreasing = T),]
mean_of_replicas = as.data.frame(apply(dfnorm[, c(2:101)], 1, mean))
sd_of_replicas = as.data.frame(apply(dfnorm[, c(2:101)], 1, sd))
data2plot = cbind(dfnorm[, 'origin'], mean_of_replicas, sd_of_replicas, rownames(dfnorm))
colnames(data2plot) = c('origin', 'mean', 'sd', 'tax')
sink(paste0(projectName , '.', 'scatter_lm_taxonomy_subset_comparisons_100replicas.txt'))
print(summary(lm(data2plot$origin ~ data2plot$sd)))
sink()
p = ggplot(data2plot, aes(origin, mean)) + theme_light()
#p = p + geom_point() + geom_text(aes(label=tax),hjust=0, vjust=0)
p = p + geom_point() + geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd))
# Add regression line
p = p + geom_smooth(method = lm, formula = y ~ x)
p = p + geom_text(data = data2plot[data2plot$mean > 1,], aes(origin, mean, label = tax), hjust = 0, vjust = 0, size = 3)
p = p + labs(title = 'Subsetting taxa for an specific environment: \'Aquatic Freshwaters\'', x = 'Frequency of the different taxa in the reference of \'Aquatic Freshwaters\'', y = 'Mean of taxa abundance in 100 mocks of \'Aquatic Freshwaters\'')
p = p + theme(plot.title = element_text(hjust = 0.5))
p
p = ggplot(data2plot, aes(origin, mean)) + theme_light()
#p = p + geom_point() + geom_text(aes(label=tax),hjust=0, vjust=0)
p = p + geom_point() + geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), col = 'gray')
# Add regression line
p = p + geom_smooth(method = lm, formula = y ~ x)
p = p + geom_text(data = data2plot[data2plot$mean > 1,], aes(origin, mean, label = tax), hjust = 0, vjust = 0, size = 3)
p = p + labs(title = 'Subsetting taxa for an specific environment: \'Aquatic Freshwaters\'', x = 'Frequency of the different taxa in the reference of \'Aquatic Freshwaters\'', y = 'Mean of taxa abundance in 100 mocks of \'Aquatic Freshwaters\'')
p = p + theme(plot.title = element_text(hjust = 0.5))
p
p = ggplot(data2plot, aes(origin, mean)) + theme_light()
#p = p + geom_point() + geom_text(aes(label=tax),hjust=0, vjust=0)
p = p + geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), col = 'gray') + geom_point()
# Add regression line
p = p + geom_smooth(method = lm, formula = y ~ x)
p = p + geom_text(data = data2plot[data2plot$mean > 1,], aes(origin, mean, label = tax), hjust = 0, vjust = 0, size = 3)
p = p + labs(title = 'Subsetting taxa for an specific environment: \'Aquatic Freshwaters\'', x = 'Frequency of the different taxa in the reference of \'Aquatic Freshwaters\'', y = 'Mean of taxa abundance in 100 mocks of \'Aquatic Freshwaters\'')
p = p + theme(plot.title = element_text(hjust = 0.5))
p
setwd("~/opt/MMs/tests/test4/distances")
library('reshape2')
library('ggplot2')
library('dplyr')
library('data.table')
data2plot = list()
d2plot_basic = as.data.frame(matrix(0, nrow = 100, ncol = 4))
colnames(d2plot_basic) = c('R','meanASVs', 'sdASVs', 'originalASVs')
projectName = 'Freshwaters2_master_asvsmean'
j = 1
for (asv in 1:10){
for (i in 1:10){ ###### trial
ASV = paste0('ASV_', asv)
R = paste0('R_', i)
finalFile = paste0(projectName , '_', asv, '.', i, '.distances.tsv')
distances = read.table(finalFile, row.names = 1, header = T, stringsAsFactors = F,  sep = '\t', check.names = F)
ind = which(upper.tri(distances, diag = TRUE), arr.ind = TRUE)
M = cbind(ind, distances[ind])
data = as.data.frame(M)
data[,'row'] = rownames(distances)[unname(data[,'row'])]
data[,'col'] = colnames(distances)[unname(data[,'col'])]
colnames(data) = c('seq1','seq2','d')
data$species1 = paste0(sapply(strsplit(data$seq1, '[.]'), "[", 1), '.', sapply(strsplit(data$seq1, '[.]'), "[", 2))
data$species2 = paste0(sapply(strsplit(data$seq2, '[.]'), "[", 1), '.', sapply(strsplit(data$seq2, '[.]'), "[", 2))
# Remove seq1==seq2
data2 = data[!(data$seq1==data$seq2),]
df = as.data.frame(matrix(0, nrow = length(levels(as.factor(data2$species1))), ncol = 6))
colnames(df) = c('Sp', 'max_distance', 'min_distance', 'nASVsperSp', 'ASVs', 'OriginalASVs')
rownames(df) = levels(as.factor(data2$species1))
for (sp in levels(as.factor(data2$species1))){
if (dim(data2[data2$species1 == sp & data2$species2 == sp,])[1] > 0){
max_distance = max(data2[data2$species1 == sp & data2$species2 == sp,'d'])
min_distance = min(data2[data2$species1 == sp & data2$species2 == sp,'d'])
dumb = data2[data2$species1 == sp & data2$species2 == sp, c('seq1','seq2')]
nASVsperSp = length(unique(c(dumb$seq1, dumb$seq2)))
df[sp, 'Sp'] = sp
df[sp,'max_distance'] = max_distance
df[sp, 'min_distance'] = min_distance
df[sp, 'nASVsperSp'] = as.numeric(nASVsperSp) #not count the original reference
df[sp, 'ASVs'] = paste(unique(c(dumb$seq1, dumb$seq2)), collapse = ',')
df[sp, 'OriginalASVs'] = asv
}
else{df[sp,] = c(sp, 0, 0, 1,sp, asv)}
}
data2plot[[ASV]][[R]] = df
d2plot_basic[j, ] = c(R, mean(as.numeric(df$nASVsperSp), na.rm=TRUE), sd(as.numeric(df$nASVsperSp), na.rm=TRUE), df$OriginalASVs)
j=j+1
}
}
d2plot_basic$meanASVs = as.numeric(d2plot_basic$meanASVs)
d2plot_basic$sdASVs = as.numeric(d2plot_basic$sdASVs)
d2plot_basic$originalASVs = factor(d2plot_basic$originalASVs, levels = c(1:10))
sink(paste0(projectName , '.', 'average_ASVs.txt'))
print(summary(lm(as.numeric(originalASVs) ~ meanASVs, data = d2plot_basic)))
sink()
coefs = coef(lm(as.numeric(originalASVs) ~ meanASVs, data = d2plot_basic))
p = ggplot(d2plot_basic, aes(x = originalASVs, y = meanASVs))  + theme_light()
p = p + geom_boxplot() + scale_y_continuous(breaks = c(1:10))
p = p + labs(title = 'Average number of ASVs', x = 'Requested average number of ASVs', y = 'Average number of ASVs per species')
p = p + theme(plot.title = element_text(hjust = 0.5))
p = p + geom_abline(intercept = coefs[1], slope = coefs[2], color = "red")
p
